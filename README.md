# 🗓️ 30 DAYS OF DATA SETS

This repository documents my 30-day data analysis challenge, where I explore a new dataset each day to improve my skills in data cleaning, analysis, and visualization.

Each folder (Day 1, Day 2, etc.) contains:

The dataset used

SQL queries or Python notebooks for analysis

Notes and observations

Screenshots of results

# 💡 GOAL:
To strengthen my understanding of data manipulation, querying, and storytelling using real-world datasets.

🛠️ TOOLS AND TECHNOLOGIES:

SQL (Azure Data Studio)

Excel / CSV Datasets

Git & GitHub for version control

# 📅 DAY 1 PROJECT:
Earthquake Data (Tsunami Impact Analysis) — A study of earthquake records and their relationships with tsunami occurrences. This analysis includes querying magnitude, depth, yearly trends, and tsunami frequency using SQL.
